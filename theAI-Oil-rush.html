<!DOCTYPE HTML>
<!--
	Dimension by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html prefix="og: http://ogp.me/ns#">
	<head>
 	<title>The AI Oil Rush</title>
    <meta property="og:url"      content="https://murchie85.github.io/theAI-Oil-rush.html" />
    <meta property="og:type"          content="website" />
    <meta property="og:title" content="The AI Oil Rush - Repeating our same mistakes." />
    <meta prefix="og: http://ogp.me/ns#" charset="utf-8" />
    <meta itemprop="image" content="images/oil.png" />   <!-- PREVIEW IMAGE -->
    <meta prefix="og: http://ogp.me/ns#" property="og:image" content="images/oil.png"> <!-- PREVIEW IMAGE -->
    <meta prefix="og: http://ogp.me/ns#" property="og:description" content="The rush to build AI systems with no explainability is motivated by the desire to obtain short-term value without considering the long-term implications. This pursuit of short-term value comes at a cost, as the lack of explainability in AI systems can have real-world consequences, such as bias and inadequate performance, and may have long-term consequences that we are not yet aware of.">
    <meta prefix="og: http://ogp.me/ns#" name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
    <link rel="stylesheet" href="assets/css/main.css" />
    <link rel="stylesheet" type="text/css" href="http://fonts.googleapis.com/css?family=Tangerine">
    <!--[if lte IE 9]><link rel="stylesheet" href="assets/css/ie9.css" /><![endif]-->
    <noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>


	</head>

	<body>

		<!-- Facebook Like Code -->

    <div id="fb-root"></div>
    <script>(function(d, s, id) {
        var js, fjs = d.getElementsByTagName(s)[0];
        if (d.getElementById(id)) return;
        js = d.createElement(s); js.id = id;
        js.src = 'https://connect.facebook.net/en_GB/sdk.js#xfbml=1&version=v2.12&appId=1751839964842666&autoLogAppEvents=1';
        fjs.parentNode.insertBefore(js, fjs);
    }(document, 'script', 'facebook-jssdk'));</script>


		<!-- Tweet Code -->
<script>window.twttr = (function(d, s, id) {
  var js, fjs = d.getElementsByTagName(s)[0],
    t = window.twttr || {};
  if (d.getElementById(id)) return t;
  js = d.createElement(s);
  js.id = id;
  js.src = "https://platform.twitter.com/widgets.js";
  fjs.parentNode.insertBefore(js, fjs);

  t._e = [];
  t.ready = function(f) {
    t._e.push(f);
  };

  return t;
}(document, "script", "twitter-wjs"));</script>



		<!-- Wrapper -->
			<div id="wrapper">



				<div id="blogs">
					<article id="Blog">

				<!-- Header -->
					<header id="header">
						<div class="content">
							<div class="inner">
								<a href="index.html"><h1>The AI Oil Rush</h1></a>
							</div>
						</div>
					</header>
					<br>

						<center><span class="image med"><img src="images/oil.png" alt="DevOps"></span></center>
										<center> <i>The rush for oil transformed our world, but it also changed who we were as a people - and made transitioning to alternatives nearly impossible.</i></center><br>
	

<div>

<div class="fb-like" data-href="https://murchie85.github.io/theAI-Oil-rush.html" data-layout="button_count" data-action="like" data-size="small" data-show-faces="true" data-share="true"></div> <a class="twitter-share-button" href="https://twitter.com/intent/tweet?text=The AI Oil rushs"> Tweet</a></div><br><br> 



<p>The rush to build AIs is similar to the oil rush in that it is driven by the desire to obtain short-term value without considering the long-term implications. Just as the oil rush led to the rapid extraction and consumption of fossil fuels without adequate regard for the environmental consequences, the rush to build AI systems has driven us down the direction of unexplainable AI leading to the development of complex and opaque algorithms that are difficult to understand and manage. </p>
<p>This isn't simply a biproduct of complex design, but rather an <b><u>inherent flaw</u></b> conventional neural networks which produce blackbox models and whilst hundreds of tech companies have worked to address this, the fundamental issue still persists.</p>

<div id="quote"><center>
    <b style = "font-size:190%;color:orange">“Sustainabile AI, means AI that can pass the test of time, this means being intelligible and ethical. Not opaque and subject to bias. ”
    </b>
    </center>
    <i>A McMurchie</i>
    <br> <br>
    </div>

<p>Like the oil rush, the AI rush is motivated by the promise of <b>immediate rewards</b>. AI systems that are trained on large amounts of data can often produce impressive results, such as accurate predictions or efficient decision-making. However, like the oil rush, this pursuit of short-term value comes at a cost. The lack of explainability in AI systems can make it difficult to understand why they make certain decisions, which can lead to issues such as bias or inadequate performance in edge cases. Additionally, the lack of explainability can make it <b>difficult to debug</b> or improve these systems over time, limiting their potential value in the long run.</p>
    
<p> Just as the oil rush has had lasting environmental consequences that we are still grappling with today, the rush to build AI systems without explainability may have long-term consequences that we are not yet aware of. It is important for us to consider these implications and to ensure that we are building AI systems in a responsible and sustainable way. This may require a shift in focus from short-term gains to long-term value and sustainability.</p>
    
    
    
    

<p>There are many examples that demonstrate the challenges and consequences of building AI systems with no explainability. For instance, a study published in the journal Science found that an AI system trained to predict the likelihood of reoffending by criminal defendants was <b>biased against African American defendants</b>. This bias was not apparent when examining the AI system's output, but it became apparent when researchers looked at how the AI system made its decisions. In this case, the lack of explainability in the AI system made it difficult to identify and address the bias.</p>
    
<p>Another example is the use of AI systems in medical diagnosis. AI systems that are trained on large amounts of medical data can often produce accurate diagnoses, but their lack of explainability can make it difficult for doctors to understand why the AI system made a particular diagnosis. This can be problematic in cases where the AI system <b>makes an incorrect diagnosis</b>, as it can be difficult for doctors to determine why the AI system made the mistake and how to correct it.</p>
    
<p>Overall, these examples demonstrate that the lack of explainability in AI systems can have real-world consequences, such as bias and inadequate performance. It is therefore important for us to consider the long-term implications of building AI systems without explainability and to ensure that we are building AI systems in a responsible and sustainable way.</p>
    
    
    
<p>It is difficult to predict the long-term consequences of building AI systems with no explainability, as the field of AI is rapidly evolving and the potential implications of these systems are not yet fully understood. However, some potential long-term consequences include the following:</p>
    
<h2>Inadequate performance </h2>
<p> AI systems that are not transparent and explainable may not perform well in edge cases or in situations where their input data is not representative of the real world. This can lead to incorrect or inadequate decisions, which can have serious consequences, such as in the case of medical diagnosis or financial decision-making.</p>
    
<h2> Bias and discrimination</h2>
<p> AI systems that are not explainable may be more likely to incorporate bias and discrimination into their decision-making. For example, an AI system that is trained on biased data may produce decisions that reflect that bias. This can lead to unfair treatment of certain groups of people, such as those based on race, gender, or other factors.</p>

<h2>Lack of trust</h2>
<p>The lack of explainability in AI systems can make it difficult for people to trust and understand these systems. This can lead to a lack of adoption and acceptance of AI technology, which can limit its potential value and impact.</p>
<h2>Difficulty improving and adapting</h2> 

<p>The lack of explainability in AI systems can make it difficult to understand and improve these systems over time. This can limit their ability to adapt to changing conditions and may make them less valuable and relevant in the long run.</p>

<p>Overall, the long-term consequences of building AI systems with no explainability are likely to be significant and far-reaching. It is therefore important for us to consider these implications and to ensure that we are building AI systems in a responsible and sustainable way.</p>

<h2>Solving the Problem</h2>

<p>So where does that leave us? The problem is similar to the electric car dillema in the early 1900s, in that it just didn't prove appealing enough an alternative. Yet 100 years later we are finally transitioning away from petrol back to electric. This may be the same story with AI, rather than spend 100 years bogged down in ethics quagmire, engineers should devote their time to more innovative solutions. <br> This can include things such as: 
<ul>
    <li>Mixing classical procedural coding with neural networks. A Rules-Net fusion, something I personally have already produced on my assistant AI</li>
    <li>Setting limits, rules and regulation on the way data is extracted, cleaned and processed - there is a lot of work in this space, currently its very confusing but could become mainstream litterature and best pracices.</li>
    <li>Designing a completley new form of AI, one that doesn't behave in the conventional deep learning sense: again I have two models that do not rely on hidden weights, watch this space.</li>

</ul>
</p>

<p>Ultimately the tech space is the fastest growing professional industry on the planet, to take a glass is half full approach, it should be a matter of time before better alternatives emerge - we just need to have been moderate enough to enable us to wean ourselves off and make the transition. </p>

    
    
    
    
</p>


									<center><div id="start"> <h2> Thanks for Reading</h2> </div></center> 




<br><strong> Adam McMurchie  11/Dec/2022 </strong>
<br><br>


		<!-- **************************footer picture goes here *********************************************** -->

								<span class="image main"><img src="images/blog/pic02.jpg" alt="" /></span>
							</article>
					</div>

				<!-- Main -->


				<!-- Footer -->
					<footer id="footer">
						<p class="copyright">&copy; Adam. McMurchie: <a href="https://html5up.net">Project</a>.</p>
					</footer>

			</div>

		<!-- **************************background picture goes here *********************************************** -->
			<div id="bg2"></div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/skel.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>
